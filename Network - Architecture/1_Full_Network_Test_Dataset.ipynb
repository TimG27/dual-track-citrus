{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"RC7kDo41fztO"},"outputs":[],"source":["from google.colab import drive\n","import shutil\n","import torch\n","from torchvision import transforms\n","import torchvision\n","from torch.utils.data import DataLoader\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JXcOVtQCUVh3"},"outputs":[],"source":["import zipfile\n","import os"]},{"cell_type":"markdown","metadata":{"id":"RY5BLxHDU80X"},"source":["Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":231926,"status":"ok","timestamp":1674639892261,"user":{"displayName":"Timothy George","userId":"02763915376707504836"},"user_tz":-330},"id":"cLUFbE9qUX_Y","outputId":"4dc19d67-c2fa-4073-9be0-adeb94e531c2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"]}],"source":["drive.mount ('/content/gdrive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vY_t6_ByN6-4"},"outputs":[],"source":["batch_size = 4"]},{"cell_type":"markdown","metadata":{"id":"-Sbn0NpR53uH"},"source":["Loading the dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1jHl-K7SgXpG"},"outputs":[],"source":["dataset_path = '/content/gdrive/MyDrive/Train-Test-Val/'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gq6wYdXvNrjH"},"outputs":[],"source":["# Transformer to tensor\n","img_size = 256\n","\n","transformer=transforms.Compose([\n","    transforms.Resize((img_size,img_size)),\n","    transforms.ToTensor(),  #0-255 to 0-1, numpy to tensors\n","])  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6Yjn6WnZOIuy"},"outputs":[],"source":["def load_dataset(d_path):\n","    train_dataset_manual = torchvision.datasets.ImageFolder(d_path, transform=transformer)\n","    train_loader_manual = torch.utils.data.DataLoader(train_dataset_manual)\n","    return train_loader_manual"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g3Qe9Cu7gv9o"},"outputs":[],"source":["train_dataset = load_dataset(str(dataset_path + 'train')).dataset\n","test_dataset = load_dataset(str(dataset_path + 'test')).dataset\n","valid_dataset = load_dataset(str(dataset_path + 'val')).dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HvLNzeEQvz8K"},"outputs":[],"source":["train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=2, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=2, shuffle=True)\n","valid_loader = DataLoader(valid_dataset, batch_size=batch_size, num_workers=2, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1674639906982,"user":{"displayName":"Timothy George","userId":"02763915376707504836"},"user_tz":-330},"id":"ZDCxH0CxvxMU","outputId":"6c7ca133-5469-4c31-9388-d659b72b3294"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train Set- 4168 images in 1042 batches\n","Testing Set - 1397 images in 350 batches\n","Validation Set - 1388 images in 347 batches\n"]}],"source":["print('Train Set- ' + str(len(train_dataset)) + ' images in ' + str(len(train_loader)) +' batches')\n","print('Testing Set - ' + str(len(test_dataset)) + ' images in ' + str(len(test_loader)) + ' batches' )\n","print('Validation Set - ' + str(len(valid_dataset)) + ' images in ' + str(len(valid_loader)) + ' batches')"]},{"cell_type":"markdown","metadata":{"id":"Vbs8qRxx5y6k"},"source":["Network"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dzY9Mu8vqY_S"},"outputs":[],"source":["class depthwise_separable_conv(nn.Module):\n","    def __init__(self, nin, nout):\n","        super(depthwise_separable_conv, self).__init__()\n","        self.depthwise = nn.Conv2d(nin, nin, kernel_size=3, padding=1, groups=nin)\n","        self.pointwise = nn.Conv2d(nin, nout, kernel_size=1)\n","\n","    def forward(self, x):\n","        out = self.depthwise(x)\n","        out = self.pointwise(out)\n","        return out\n","  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yzal0EEPro0N"},"outputs":[],"source":["class channel_shuffle (nn.Module):\n","    def __init__(self, groups):\n","      super (channel_shuffle, self).__init__()\n","      self.groups = groups\n","\n","    def forward (self, x):\n","\n","      batchsize, num_channels, height, width = x.size()\n","      channels_per_group = num_channels // self.groups\n","\n","      x = x.view(batchsize, self.groups, channels_per_group, height, width)\n","      x = torch.transpose(x, 1, 2).contiguous()\n","      x = x.view(batchsize, -1, height, width)\n","      \n","      return x\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WxgyajrBWUso"},"outputs":[],"source":["class GDSW (nn.Module):\n","  def __init__ (self, dim_in, dim_out):\n","    super(GDSW, self).__init__()\n","\n","    self.gc1 = nn.Conv2d (dim_in, 6, kernel_size = (3,3), padding = 1,  groups = 3)\n","    self.cs = channel_shuffle (groups = 3)\n","    self.DSWC = depthwise_separable_conv (6, 12)\n","    self.gc2 = nn.Conv2d (12, dim_out, kernel_size = (3, 3), padding = 1, groups = 3)\n","\n","  def forward (self, x):\n","    x = self.gc1 (x)\n","    x = self.cs(x)\n","    x = self.DSWC (x)\n","    x = self.gc2(x)\n","\n","    return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WMu3JjtF5WC8"},"outputs":[],"source":["class FPN (nn.Module):\n","  def __init__ (self):\n","    super().__init__()\n","    self.enc_conv0 = nn.Conv2d(in_channels=18, out_channels=24, kernel_size=(3,3), padding=1)\n","    self.act0 = nn.ReLU()\n","    self.bn0 = nn.BatchNorm2d(24)\n","    self.pool0 = nn.MaxPool2d(kernel_size=(2,2))\n","\n","    self.enc_conv1 = nn.Conv2d(in_channels=24, out_channels=32, kernel_size=(3,3), padding=1)\n","    self.act1 = nn.ReLU()\n","    self.bn1 = nn.BatchNorm2d(32)\n","    self.pool1 = nn.MaxPool2d(kernel_size=(2,2))\n","\n","    self.enc_conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3), padding=1)\n","    self.act2 = nn.ReLU()\n","    self.bn2 = nn.BatchNorm2d(64)\n","    self.pool2 =  nn.MaxPool2d(kernel_size=(2,2))\n","\n","    self.bottleneck_conv = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), padding=1)\n","\n","    self.upsample2 = nn.UpsamplingBilinear2d(scale_factor=2)\n","    self.dec_conv2 = nn.Conv2d(in_channels=192, out_channels=32, kernel_size=(3,3), padding=1)\n","    self.dec_act2 = nn.ReLU()\n","    self.dec_bn2 = nn.BatchNorm2d(32)\n","\n","    self.upsample3 = nn.UpsamplingBilinear2d(scale_factor=2)\n","    self.dec_conv3 = nn.Conv2d(in_channels=64, out_channels=16, kernel_size=(3,3), padding=1)\n","    self.dec_act3 = nn.ReLU()\n","    self.dec_bn3 = nn.BatchNorm2d(16)\n","\n","    self.upsample4 = nn.UpsamplingBilinear2d(scale_factor=2)\n","    self.dec_conv4 = nn.Conv2d(in_channels=40, out_channels=32, kernel_size=(1,1))\n","    self.dec_act4 = nn.ReLU()\n","    self.dec_bn4 = nn.BatchNorm2d(32)\n","\n","    self.poolg = nn.MaxPool2d(kernel_size=(2,2))\n","    self.avgpool = nn.AdaptiveAvgPool2d (8)\n","\n","  def forward (self, x):\n","\n","    e0 = self.pool0(self.bn0(self.act0(self.enc_conv0(x))))   \n","    e1 = self.pool1(self.bn1(self.act1(self.enc_conv1(e0))))   \n","    e2 = self.pool2(self.bn2(self.act2(self.enc_conv2(e1))))   \n","\n","    cat0 = self.bn0(self.act0(self.enc_conv0(x)))\n","    cat1 = self.bn1(self.act1(self.enc_conv1(e0)))      \n","    cat2 = self.bn2(self.act2(self.enc_conv2(e1)))\n","\n","    b = self.bottleneck_conv(e2)\n","\n","    d2 = self.dec_bn2(self.dec_act2(self.dec_conv2(torch.cat((self.upsample2(b), cat2), dim=1))))\n","    d3 = self.dec_bn3(self.dec_act3(self.dec_conv3(torch.cat((self.upsample3(d2), cat1), dim=1))))\n","    d4 = self.dec_bn4(self.dec_act4(self.dec_conv4(torch.cat((self.upsample4(d3), cat0), dim=1))))\n","\n","    return d4"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xEsNDFg71JsT"},"outputs":[],"source":["class CNN_Branch(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.GDSW1 = GDSW(dim_in = 3, dim_out = 6)\n","        self.GDSW2 = GDSW(dim_in = 6, dim_out = 9)\n","        self.GDSW3 = GDSW(dim_in = 9, dim_out = 12)\n","\n","        self.bnn1 = nn.BatchNorm2d (6)\n","        self.bnn2 = nn.BatchNorm2d (9)\n","        self.bnn3 = nn.BatchNorm2d (12)\n","\n","        self.FPN = FPN ()\n","\n","        self.poolg = nn.MaxPool2d(kernel_size=(2,2))\n","        self.poolg4 = nn.MaxPool2d(kernel_size=(4,4))\n","        self.avgpool = nn.AdaptiveAvgPool2d (8)\n","\n","        self.fc = nn.Linear(128 * img_size, 7)        \n","\n","    def forward(self, x):\n","\n","        g0 = self.poolg(self.bnn1(self.GDSW1(x)))        \n","        g1 = self.poolg(self.bnn2(self.GDSW2(g0)))        \n","        g2 = self.poolg(self.bnn3(self.GDSW3(g1)))        \n","\n","        g3 = torch.cat ((self.poolg4(g0), g2), dim = 1)\n","        d4 = self.FPN (g3)\n","        d4 = self.poolg4 (d4)\n","\n","        return d4"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KQ7kdptaYLgI"},"outputs":[],"source":["class Transformer_Branch (nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.SWIN = torchvision.models.swin_b()\n","        self.SWIN.avgpool = nn.Identity()\n","        self.SWIN.flatten = nn.Identity()\n","        self.SWIN.head = nn.Identity()\n","\n","    def forward (self, x):\n","\n","      x = self.SWIN (x)\n","\n","      return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tq9WQqUXZ1X3"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.nn.parameter import Parameter\n","\n","class sa_layer(nn.Module):\n","    def __init__(self, channel, groups=66):\n","        super(sa_layer, self).__init__()\n","        self.groups = groups\n","        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n","        self.cweight = Parameter(torch.zeros(1, channel // (2 * groups), 1, 1))\n","        self.cbias = Parameter(torch.ones(1, channel // (2 * groups), 1, 1))\n","        self.sweight = Parameter(torch.zeros(1, channel // (2 * groups), 1, 1))\n","        self.sbias = Parameter(torch.ones(1, channel // (2 * groups), 1, 1))\n","\n","        self.sigmoid = nn.Sigmoid()\n","        self.gn = nn.GroupNorm(channel // (2 * groups), channel // (2 * groups))\n","\n","    @staticmethod\n","    def channel_shuffle(x, groups):\n","        b, c, h, w = x.shape\n","\n","        x = x.reshape(b, groups, -1, h, w)\n","        x = x.permute(0, 2, 1, 3, 4)\n","\n","        # flatten\n","        x = x.reshape(b, -1, h, w)\n","\n","        return x\n","\n","    def forward(self, x):\n","        b, c, h, w = x.shape\n","\n","        x = x.reshape(b * self.groups, -1, h, w)\n","        x_0, x_1 = x.chunk(2, dim=1)\n","\n","        # channel attention\n","        xn = self.avg_pool(x_0)\n","        xn = self.cweight * xn + self.cbias\n","        xn = x_0 * self.sigmoid(xn)\n","\n","        # spatial attention\n","        xs = self.gn(x_1)\n","        xs = self.sweight * xs + self.sbias\n","        xs = x_1 * self.sigmoid(xs)\n","\n","        # concatenate along channel axis\n","        out = torch.cat([xn, xs], dim=1)\n","        out = out.reshape(b, -1, h, w)\n","\n","        out = self.channel_shuffle(out, 2)\n","        return out\n","    \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nkBaOV5haAnt"},"outputs":[],"source":["class Overall_Arch (nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.CNN_Branch = CNN_Branch()\n","        self.Transformer_Branch = Transformer_Branch()\n","        self.SA_Block = sa_layer(channel = 1056)\n","\n","        self.gap = nn.AvgPool2d (kernel_size = (8,8))\n","        self.fc = nn.Sequential (nn.Linear (1056, 7), nn.Softmax(dim=1))\n"," \n","    \n","    def forward (self, x):\n","\n","      local_f = self.CNN_Branch (x)\n","      global_f = self.Transformer_Branch(x)\n","      fused_f = torch.cat ([local_f, global_f], dim = 1)\n","\n","      fused_f = self.SA_Block (fused_f)\n","      f = self.gap (fused_f)\n","\n","      f = torch.flatten (f, 1)\n","      f = self.fc (f)\n","\n","      return f"]},{"cell_type":"markdown","metadata":{"id":"9RpROOR567ZA"},"source":["Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_L7XGZBGDsjj"},"outputs":[],"source":["if torch.cuda.is_available():\n","  torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1674639907623,"user":{"displayName":"Timothy George","userId":"02763915376707504836"},"user_tz":-330},"id":"UReKif_NCwnR","outputId":"2e775e1c-7e73-4c02-8bd5-ab6df053bf6d"},"outputs":[{"data":{"text/plain":["device(type='cuda', index=0)"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","device"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C8U-i6rz68Fr"},"outputs":[],"source":["model = Overall_Arch().to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aGbQJU02ZF3p"},"outputs":[],"source":["#Load latest model\n","save_path = '/content/gdrive/MyDrive/Train-Test-Val/Epochn35'\n","model = torch.load(save_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kDz32NvZ68el"},"outputs":[],"source":["model.eval()"]},{"cell_type":"markdown","metadata":{"id":"5gIY0bpsNvg-"},"source":["Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m93749b2JG_s"},"outputs":[],"source":["from sklearn.metrics import classification_report, accuracy_score\n","import seaborn as sn\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5pxJfUoBJKkk"},"outputs":[],"source":["y_pred = []\n","y_true = []\n","\n","# iterate over test data\n","for i, (images, labels) in enumerate(test_loader):\n","    images, labels = images.to(device), labels.to(device)\n","\n","    output = model(images) # Feed Network\n","\n","    output = (torch.max(torch.exp(output), 1)[1])\n","    output = output.data.cpu().numpy()\n","\n","    y_pred.extend(output) # Save Prediction\n","        \n","    labels1 = labels.data.cpu().numpy()\n","    y_true.extend(labels1) # Save Truth"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yfD3E-vNJQeZ"},"outputs":[],"source":["r = classification_report(y_true, y_pred,zero_division=0,output_dict=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":451,"status":"ok","timestamp":1674640099610,"user":{"displayName":"Timothy George","userId":"02763915376707504836"},"user_tz":-330},"id":"uzHhfaSGUSNK","outputId":"ef9a41d3-6b03-475e-89eb-acb923e46418"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy -  0.7430207587687903\n","Weighted Average -  {'precision': 0.6072968325168648, 'recall': 0.7430207587687903, 'f1-score': 0.6671792962913379, 'support': 1397}\n","Macro Average -  {'precision': 0.3188943398935498, 'recall': 0.3911214377737827, 'f1-score': 0.3507525565623589, 'support': 1397}\n"]}],"source":["print ('Accuracy - ', r.get ('accuracy'))\n","print ('Weighted Average - ', r.get('weighted avg'))\n","print ('Macro Average - ', r.get('macro avg'))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["### References:\n","\n","### [1] Adeel H, “Focal Loss,” GitHub, https://github.com/AdeelH/pytorch-multi-class-focal-loss/blob/master/focal_loss.py \n","### [2] wofmanaf, “SA-Net,” GitHub, https://github.com/wofmanaf/SA-Net/blob/main/models/sa_resnet.py  \n","### [3] Microsoft, “Semantic Segmentation Pytorch,” GitHub, https://github.com/microsoft/AI-For-Beginners/blob/main/lessons/4-ComputerVision/12-Segmentation/SemanticSegmentationPytorch.ipynb \n","### [4] Beijing Technology and Business University, “Fe-net,” GitHub, https://github.com/btbuIntelliSense/Fe-net/blob/main/Model/FENet.py\n","### [5] Shicai, “How to modify a conv2d to depthwise separable convolution?,” PyTorch Forums, https://discuss.pytorch.org/t/how-to-modify-a-conv2d-to-depthwise-separable-convolution/15843/7"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
